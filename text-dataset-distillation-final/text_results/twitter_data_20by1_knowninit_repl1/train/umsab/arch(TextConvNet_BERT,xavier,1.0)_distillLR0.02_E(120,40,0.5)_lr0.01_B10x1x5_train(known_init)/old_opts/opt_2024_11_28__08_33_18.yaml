add_first: true
add_label_scaling: 0
arch: TextConvNet_BERT
attack_class: 0
base_seed: 1
batch_size: 1024
checkpoint_interval: 10
dataset: umsab
dataset_labels: !!set
    0: null
    1: null
    2: null
dataset_normalization: !!python/tuple
- &id001 !!python/tuple
    - 0
- *id001
dataset_root: ./data/text/umsab
decay_epochs: 40
decay_factor: 0.5
device_id: 0
dist_metric: MSE
distill_epochs: 5
distill_lr: 0.02
distill_steps: 1
distilled_images_per_class_per_step: 10
distributed: false
dropout: false
epochs: 120
expr_name_format: null
freeze_data: false
image_dpi: 80
init: xavier
init_labels:
- 0
- 1
- 2
init_param: 1.0
input_size: 400
invert_dist: false
label_softmax: false
learnable_embedding: false
log_file: text_results/umsab_20by1_knowninit_repl1\train\umsab\arch(TextConvNet_BERT,xavier,1.0)_distillLR0.02_E(120,40,0.5)_lr0.01_B10x1x5_train(known_init)\output.log
log_interval: 100
log_level: INFO
lr: 0.01
maxlen: 400
mode: train
model_dir: ./models/
model_subdir_format: null
mult_label_scaling: 1
n_nets: 1
nc: 1
ninp: 50
no_log: false
ntoken: 251639
num_classes: 3
num_distill_classes: 3
num_workers: 8
phase: train
random_init_labels: ''
reproduction_test: false
results_dir: text_results/umsab_20by1_knowninit_repl1
sample_n_nets: 1
source_dataset: null
start_time: '2024-11-28 08:33:18'
static_labels: 0
target_class: 1
test_batch_size: 1024
test_distill_epochs: null
test_distilled_images: loaded
test_distilled_lrs:
- loaded
test_n_nets: 1
test_n_runs: 1
test_name_format: null
test_nets_type: same_as_train
test_niter: 1
test_optimize_n_nets: 20
test_optimize_n_runs: null
textdata: false
train_nets_type: known_init
visualize: true
world_rank: 0
world_size: 1
